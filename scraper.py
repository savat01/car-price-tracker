from playwright.sync_api import sync_playwright
import json
import os
import re


def extract_price_only_before_million(text):
    if not text:
        return None

    match = re.search(r'(\d+(\.\d+)?)\s*Ù…Ù„ÙŠÙˆÙ†', text)
    if match:
        return match.group(1)  # Ø§Ù„Ø±Ù‚Ù… ÙÙ‚Ø· ÙƒÙ†Øµ
    return None


def scroll_and_wait(page, scrolls=3):
    for i in range(scrolls):
        page.evaluate(f"window.scrollTo(0, {i * 500});")
        page.wait_for_timeout(1500)
    page.evaluate("window.scrollTo(0, document.body.scrollHeight);")
    page.wait_for_timeout(2000)
    page.evaluate("window.scrollTo(0, 0);")
    page.wait_for_timeout(1000)


def scrape_dzairauto(page):
    cars = []
    try:
        url = "https://dzairauto.net/Voitures-occasion-avendre"
        print(f"\nðŸ“ DzairAuto: {url}")
        page.goto(url, wait_until="domcontentloaded", timeout=30000)
        page.wait_for_timeout(4000)
        scroll_and_wait(page)
        
        selectors = [
            "div.d-flex.justify-content-end.text-right",
            "div[class*='d-flex'][class*='justify-content-end'][class*='text-right']",
            ".d-flex.justify-content-end.text-right"
        ]
        
        listings = []
        for selector in selectors:
            try:
                elements = page.query_selector_all(selector)
                if elements:
                    listings = elements
                    print(f"  ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(elements)} Ø¹Ù†ØµØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…: {selector}")
                    break
            except:
                continue
        
        if not listings:
            print("  âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©")
            return []
        
        for idx, listing in enumerate(listings[:50], 1):
            try:
                content = listing.inner_text().strip()
                price = extract_price_only_before_million(content) or "ØºÙŠØ± Ù…ØªÙˆÙØ±"
                name = None
                try:
                    title_elem = listing.evaluate("""
                        el => {
                            const parent = el.closest('div[class*="card"], article, div[class*="item"]');
                            if (parent) {
                                const title = parent.querySelector('h5, h4, h3, h2, a, .title, [class*="title"]');
                                return title ? title.innerText.trim() : null;
                            }
                            return null;
                        }
                    """)
                    if title_elem:
                        name = title_elem
                except:
                    pass
                if not name:
                    lines = content.split('\n')
                    name = lines[0].strip() if lines else content[:100]
                
                car_data = {
                    "content": content,
                    "price": price,
                    "name": name,
                    "source": "DzairAuto"
                }
                cars.append(car_data)
                if idx <= 3:
                    print(f"  [{idx}] {name} - Ø§Ù„Ø³Ø¹Ø±: {price}")
            except Exception as e:
                print(f"  Ø®Ø·Ø£ ÙÙŠ Ø¹Ù†ØµØ± {idx}: {e}")
                continue
                
        print(f"  âœ… Ø¬Ù…Ø¹Øª {len(cars)} Ø³ÙŠØ§Ø±Ø© Ù…Ù† DzairAuto")
        return cars
    except Exception as e:
        print(f"  âŒ Ø®Ø·Ø£: {e}")
        import traceback
        traceback.print_exc()
        return []


def gather_prices_from_dzairauto(headless=True):
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=headless)
        context = browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        page = context.new_page()
        cars = scrape_dzairauto(page)
        browser.close()
        return cars


def save_to_json(data, filename="latest_car_prices.json"):
    # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ØµØ­ÙŠØ­ Ø¯Ø§Ø®Ù„ Ù…Ø¬Ù„Ø¯ repo ÙÙŠ Ø¨ÙŠØ¦Ø© GitHub Actions
    os.makedirs("car-price-tracker/data", exist_ok=True)
    filepath = os.path.join("car-price-tracker", "data", filename)
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    return filepath


if __name__ == "__main__":
    print("=" * 70)
    print("ðŸš— Ø¨Ø¯Ø¡ Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙŠØ§Ø±Ø§Øª Ù…Ù† Ù…ÙˆÙ‚Ø¹ DzairAuto")
    print("=" * 70)

    all_cars = gather_prices_from_dzairauto(headless=True)

    if all_cars:
        print(f"âœ… ØªÙ… Ø¬Ù…Ø¹ {len(all_cars)} Ø³ÙŠØ§Ø±Ø©!")
    else:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø¬Ù…Ø¹ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª.")

    filepath = save_to_json(all_cars)
    print(f"\nðŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ: {filepath}")
